{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TUGAS BESAR KULIAH SISTEM PENGUKURAN BERBASIS CITRA\n",
    "Nama :  Ronggur Mahendra Widya Putra\n",
    "\n",
    "NIM  :  13519008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Library\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 \n",
    "import os\n",
    "import numpy as np\n",
    "import scipy\n",
    "from skimage import color, data, restoration\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from random import uniform\n",
    "from tensorflow.keras.layers import BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data dari folder ./Data/ClassifiedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3088 files belonging to 24 classes.\n",
      "Using 2780 files for training.\n",
      "Found 3088 files belonging to 24 classes.\n",
      "Using 308 files for validation.\n",
      "Found 312 files belonging to 24 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ClassifiedDataDir = \"./Data/ClassifiedData/Train\"\n",
    "BATCH_SIZE = 32 \n",
    "IMG_SIZE = (128, 128)\n",
    "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    directory = ClassifiedDataDir,\n",
    "        labels='inferred',\n",
    "        label_mode='int',\n",
    "        class_names=None,\n",
    "        color_mode='rgb',\n",
    "        batch_size=BATCH_SIZE,\n",
    "        image_size=IMG_SIZE,\n",
    "        shuffle=True,\n",
    "        seed=1234,\n",
    "        subset=\"training\",\n",
    "        validation_split=0.1,\n",
    "        interpolation='bilinear',\n",
    "        follow_links=False,\n",
    "        crop_to_aspect_ratio=False,\n",
    "        # rescale = 1./255,\n",
    "    )\n",
    "validation_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    directory = ClassifiedDataDir,\n",
    "        labels='inferred',\n",
    "        label_mode='int',\n",
    "        class_names=None,\n",
    "        color_mode='rgb',\n",
    "        batch_size=BATCH_SIZE,\n",
    "        image_size=IMG_SIZE,\n",
    "        shuffle=True,\n",
    "        seed=1234,\n",
    "        subset=\"validation\",\n",
    "        validation_split=0.1,\n",
    "        interpolation='bilinear',\n",
    "        follow_links=False,\n",
    "        crop_to_aspect_ratio=False,\n",
    "        # rescale = 1./255,\n",
    "    )\n",
    "\n",
    "    \n",
    "test_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    directory = \"./Data/ClassifiedData/Test\",\n",
    "        labels='inferred',\n",
    "        label_mode='int',\n",
    "        class_names=None,\n",
    "        color_mode='rgb',\n",
    "        batch_size=BATCH_SIZE,\n",
    "        image_size=IMG_SIZE,\n",
    "        shuffle=True,\n",
    "        seed=None,\n",
    "        interpolation='bilinear',\n",
    "        follow_links=False,\n",
    "        crop_to_aspect_ratio=False,\n",
    "        # rescale = 1./255,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y']\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "# for element in dataset.as_numpy_iterator():\n",
    "#     print(element)\n",
    "class_names = train_dataset.class_names\n",
    "print(class_names)\n",
    "print(len(class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Number of training batches: %d' % tf.data.experimental.cardinality(train_dataset).numpy())\n",
    "# print('Number of validation batches: %d' % tf.data.experimental.cardinality(validation_dataset).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization buffer untuk Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataSet\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Makingsure Training using GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(tf.test.is_built_with_cuda())\n",
    "print(tf.config.list_physical_devices('GPU')) \n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating CNN Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 126, 126, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 63, 63, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 61, 61, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 30, 30, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 28, 28, 64)        36928     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 50176)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 120)               6021240   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 24)                2904      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,080,464\n",
      "Trainable params: 6,080,464\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# # Model 1 Initialize\n",
    "input_size = 128\n",
    "filter_size = 14\n",
    "num_filter = 8\n",
    "maxpool_size = 2\n",
    "batch_size = BATCH_SIZE\n",
    "epochs = 30\n",
    "\n",
    "model_1 = models.Sequential()\n",
    "model_1.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(input_size, input_size, 3)))\n",
    "model_1.add(layers.MaxPooling2D((2, 2)))\n",
    "model_1.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model_1.add(layers.MaxPooling2D((2, 2)))\n",
    "model_1.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "model_1.add(tf.keras.layers.Flatten())\n",
    "model_1.add(tf.keras.layers.Dense(120))\n",
    "model_1.add(tf.keras.layers.Dense(24, activation = 'softmax'))\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "optimizer1 = tf.keras.optimizers.Nadam(\n",
    "    learning_rate=0.00001, beta_1=0.9, beta_2=0.999, epsilon=1e-07,\n",
    "    name='Nadam'\n",
    ") # 0.00001\n",
    "\n",
    "# Loss Fn\n",
    "lossfn1 = tf.keras.losses.SparseCategoricalCrossentropy( from_logits=False, reduction=tf.keras.losses.Reduction.AUTO, name='sparse_categorical_crossentropy')\n",
    "\n",
    "# Model Summary\n",
    "model_1.compile(\n",
    "    optimizer=\"rmsprop\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"sparse_categorical_accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Model 2\n",
    "\n",
    "input_size = 128\n",
    "filter_size = 3\n",
    "num_filter = 8\n",
    "maxpool_size = 2\n",
    "batch_size = BATCH_SIZE\n",
    "epochs = 30\n",
    "\n",
    "steps_per_epoch = 24720/batch_size\n",
    "\n",
    "model_2 = tf.keras.models.Sequential()\n",
    "model_2.add(tf.keras.layers.Conv2D(16, (filter_size,filter_size), \n",
    "                 input_shape= (input_size,input_size,3), \n",
    "                 activation ='relu',\n",
    "                 padding='same'))\n",
    "model_2.add(tf.keras.layers.Conv2D(16, (filter_size,filter_size), \n",
    "                 input_shape= (input_size,input_size,3), \n",
    "                 activation ='relu',\n",
    "                 padding='same'))\n",
    "model_2.add(tf.keras.layers.MaxPooling2D(pool_size=(maxpool_size, maxpool_size),strides=1))\n",
    "model_2.add(tf.keras.layers.Dropout(uniform(0, 1)))\n",
    "\n",
    "model_2.add(tf.keras.layers.Conv2D(32, (filter_size,filter_size), \n",
    "                 activation='relu', \n",
    "                 padding='valid'))\n",
    "model_2.add(tf.keras.layers.Conv2D(32, (filter_size,filter_size), \n",
    "                 activation='relu', \n",
    "                 padding='valid'))\n",
    "model_2.add(BatchNormalization())\n",
    "model_2.add(tf.keras.layers.MaxPooling2D(pool_size=(maxpool_size, maxpool_size),strides=2))\n",
    "model_2.add(tf.keras.layers.Dropout(uniform(0, 1)))  \n",
    "\n",
    "model_2.add(tf.keras.layers.Conv2D(32, (filter_size,filter_size), \n",
    "                 activation='relu', \n",
    "                 padding='valid'))\n",
    "model_2.add(tf.keras.layers.Conv2D(32, (filter_size,filter_size), \n",
    "                 activation='relu', \n",
    "                 padding='valid'))\n",
    "model_2.add(BatchNormalization())\n",
    "\n",
    "model_2.add(tf.keras.layers.Conv2D(32, (filter_size,filter_size), \n",
    "                 activation='relu', \n",
    "                 padding='valid'))\n",
    "model_2.add(tf.keras.layers.Conv2D(32, (filter_size,filter_size), \n",
    "                 activation='relu', \n",
    "                 padding='valid'))\n",
    "model_2.add(BatchNormalization())\n",
    "model_2.add(tf.keras.layers.MaxPooling2D(pool_size=(maxpool_size, maxpool_size),strides=2))\n",
    "model_2.add(tf.keras.layers.Dropout(uniform(0, 1)))  \n",
    "\n",
    "model_2.add(tf.keras.layers.Flatten())\n",
    "model_2.add(tf.keras.layers.Dense(120, activation='relu'))\n",
    "model_2.add(tf.keras.layers.Dense(120, activation='relu'))\n",
    "model_2.add(tf.keras.layers.Dense(24,activation='softmax'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 128, 128, 16)      448       \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 128, 128, 16)      2320      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 127, 127, 16)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 127, 127, 16)      0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 125, 125, 32)      4640      \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 123, 123, 32)      9248      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 123, 123, 32)     128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 61, 61, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 61, 61, 32)        0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 59, 59, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 57, 57, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 57, 57, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 55, 55, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 53, 53, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 53, 53, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 26, 26, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 26, 26, 32)        0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 21632)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 120)               2595960   \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 120)               14520     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 24)                2904      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,667,416\n",
      "Trainable params: 2,667,224\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ZEPHYRUS GU502GU\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "METRICS = [ 'sparse_categorical_accuracy']\n",
    "model_2.compile( optimizer= tf.keras.optimizers.Adam(lr=0.001),loss='sparse_categorical_crossentropy',metrics=METRICS)\n",
    "\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 3\n",
    "input_size = 128\n",
    "filter_size = 14\n",
    "num_filter = 8\n",
    "maxpool_size = 2\n",
    "batch_size = BATCH_SIZE\n",
    "epochs = 30\n",
    "\n",
    "model_3 = tf.keras.models.Sequential()\n",
    "model_3.add(tf.keras.layers.Conv2D(16, (filter_size,filter_size), \n",
    "                 input_shape= (input_size,input_size,3), \n",
    "                 activation ='relu',\n",
    "                 padding='same'))\n",
    "model_3.add(tf.keras.layers.Conv2D(32, (filter_size,filter_size), \n",
    "                 activation='relu', \n",
    "                 padding='valid'))\n",
    "model_3.add(tf.keras.layers.MaxPooling2D(pool_size=(maxpool_size, maxpool_size),strides=1))\n",
    "\n",
    "model_3.add(tf.keras.layers.Conv2D(32, (filter_size,filter_size), \n",
    "                 activation='relu', \n",
    "                 padding='valid'))\n",
    "model_3.add(tf.keras.layers.Conv2D(32, (filter_size,filter_size), \n",
    "                 activation='relu', \n",
    "                 padding='valid'))\n",
    "model_3.add(tf.keras.layers.MaxPooling2D(pool_size=(maxpool_size, maxpool_size),strides=2))\n",
    "model_3.add(tf.keras.layers.Dropout(uniform(0, 1)))  \n",
    "\n",
    "\n",
    "model_3.add(tf.keras.layers.Conv2D(64, (filter_size,filter_size), \n",
    "                 activation='relu', \n",
    "                 padding='valid'))\n",
    "model_3.add(tf.keras.layers.Conv2D(64, (filter_size,filter_size), \n",
    "                 activation='relu', \n",
    "                 padding='valid'))\n",
    "model_3.add(BatchNormalization())\n",
    "model_3.add(tf.keras.layers.MaxPooling2D(pool_size=(maxpool_size, maxpool_size),strides=2))\n",
    "model_3.add(tf.keras.layers.Dropout(uniform(0, 1)))  \n",
    "\n",
    "\n",
    "model_3.add(tf.keras.layers.Flatten())\n",
    "model_3.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "model_3.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "model_3.add(tf.keras.layers.Dense(24,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_11 (Conv2D)          (None, 128, 128, 16)      9424      \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 115, 115, 32)      100384    \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 114, 114, 32)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 101, 101, 32)      200736    \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 88, 88, 32)        200736    \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 44, 44, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 44, 44, 32)        0         \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 31, 31, 64)        401472    \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 18, 18, 64)        802880    \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 18, 18, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 9, 9, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 9, 9, 64)          0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 5184)              0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 128)               663680    \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 24)                3096      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,399,176\n",
      "Trainable params: 2,399,048\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "METRICS = [ 'sparse_categorical_accuracy']\n",
    "\n",
    "model_3.compile( optimizer= tf.keras.optimizers.Adam(lr=0.001),loss='sparse_categorical_crossentropy',metrics=METRICS)\n",
    "\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "87/87 [==============================] - 8s 51ms/step - loss: 165.8931 - sparse_categorical_accuracy: 0.4658 - val_loss: 0.5191 - val_sparse_categorical_accuracy: 0.8864\n",
      "Epoch 2/30\n",
      "87/87 [==============================] - 4s 48ms/step - loss: 3.4740 - sparse_categorical_accuracy: 0.8590 - val_loss: 0.2727 - val_sparse_categorical_accuracy: 0.9318\n",
      "Epoch 3/30\n",
      "87/87 [==============================] - 5s 49ms/step - loss: 21.3086 - sparse_categorical_accuracy: 0.8338 - val_loss: 0.4336 - val_sparse_categorical_accuracy: 0.9675\n",
      "Epoch 4/30\n",
      "87/87 [==============================] - 5s 50ms/step - loss: 2.3258 - sparse_categorical_accuracy: 0.9421 - val_loss: 0.1463 - val_sparse_categorical_accuracy: 0.9870\n",
      "Epoch 5/30\n",
      "87/87 [==============================] - 5s 50ms/step - loss: 10.2403 - sparse_categorical_accuracy: 0.9428 - val_loss: 0.4589 - val_sparse_categorical_accuracy: 0.9903\n",
      "Epoch 6/30\n",
      "87/87 [==============================] - 5s 50ms/step - loss: 2.9069 - sparse_categorical_accuracy: 0.9723 - val_loss: 0.3268 - val_sparse_categorical_accuracy: 0.9968\n",
      "Epoch 7/30\n",
      "87/87 [==============================] - 5s 54ms/step - loss: 14.2663 - sparse_categorical_accuracy: 0.9622 - val_loss: 0.8427 - val_sparse_categorical_accuracy: 0.9675\n",
      "Epoch 8/30\n",
      "87/87 [==============================] - 7s 71ms/step - loss: 5.2379 - sparse_categorical_accuracy: 0.9781 - val_loss: 1.0001 - val_sparse_categorical_accuracy: 0.9903\n",
      "Epoch 9/30\n",
      "87/87 [==============================] - 6s 64ms/step - loss: 1.6106 - sparse_categorical_accuracy: 0.9903 - val_loss: 0.2118 - val_sparse_categorical_accuracy: 0.9903\n",
      "Epoch 10/30\n",
      "87/87 [==============================] - 6s 62ms/step - loss: 0.4617 - sparse_categorical_accuracy: 0.9932 - val_loss: 0.2118 - val_sparse_categorical_accuracy: 0.9968\n",
      "Epoch 11/30\n",
      "87/87 [==============================] - 6s 64ms/step - loss: 1.9330 - sparse_categorical_accuracy: 0.9827 - val_loss: 7.3122e-04 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "87/87 [==============================] - 6s 62ms/step - loss: 1.5951 - sparse_categorical_accuracy: 0.9903 - val_loss: 0.4488 - val_sparse_categorical_accuracy: 0.9903\n",
      "Epoch 13/30\n",
      "87/87 [==============================] - 6s 64ms/step - loss: 0.9665 - sparse_categorical_accuracy: 0.9903 - val_loss: 0.0205 - val_sparse_categorical_accuracy: 0.9935\n",
      "Epoch 14/30\n",
      "87/87 [==============================] - 6s 64ms/step - loss: 0.1011 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.4912 - val_sparse_categorical_accuracy: 0.9903\n",
      "Epoch 15/30\n",
      "87/87 [==============================] - 7s 72ms/step - loss: 6.6320 - sparse_categorical_accuracy: 0.9795 - val_loss: 1.3248 - val_sparse_categorical_accuracy: 0.9903\n",
      "Epoch 16/30\n",
      "87/87 [==============================] - 7s 72ms/step - loss: 1.2581 - sparse_categorical_accuracy: 0.9942 - val_loss: 0.1248 - val_sparse_categorical_accuracy: 0.9968\n",
      "Epoch 17/30\n",
      "87/87 [==============================] - 7s 70ms/step - loss: 2.6191e-04 - sparse_categorical_accuracy: 0.9996 - val_loss: 0.0515 - val_sparse_categorical_accuracy: 0.9968\n",
      "Epoch 18/30\n",
      "87/87 [==============================] - 8s 81ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0515 - val_sparse_categorical_accuracy: 0.9968\n",
      "Epoch 19/30\n",
      "87/87 [==============================] - 8s 85ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0515 - val_sparse_categorical_accuracy: 0.9968\n",
      "Epoch 20/30\n",
      "87/87 [==============================] - 7s 77ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0515 - val_sparse_categorical_accuracy: 0.9968\n",
      "Epoch 21/30\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0515 - val_sparse_categorical_accuracy: 0.9968\n",
      "Epoch 22/30\n",
      "87/87 [==============================] - 8s 80ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0515 - val_sparse_categorical_accuracy: 0.9968\n",
      "Epoch 23/30\n",
      "87/87 [==============================] - 7s 71ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0515 - val_sparse_categorical_accuracy: 0.9968\n",
      "Epoch 24/30\n",
      "87/87 [==============================] - 7s 70ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0515 - val_sparse_categorical_accuracy: 0.9968\n",
      "Epoch 25/30\n",
      "87/87 [==============================] - 6s 68ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0515 - val_sparse_categorical_accuracy: 0.9968\n",
      "Epoch 26/30\n",
      "87/87 [==============================] - 6s 68ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0515 - val_sparse_categorical_accuracy: 0.9968\n",
      "Epoch 27/30\n",
      "87/87 [==============================] - 6s 67ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0515 - val_sparse_categorical_accuracy: 0.9968\n",
      "Epoch 28/30\n",
      "87/87 [==============================] - 6s 69ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0515 - val_sparse_categorical_accuracy: 0.9968\n",
      "Epoch 29/30\n",
      "87/87 [==============================] - 7s 77ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0515 - val_sparse_categorical_accuracy: 0.9968\n",
      "Epoch 30/30\n",
      "87/87 [==============================] - 7s 75ms/step - loss: 0.0000e+00 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0515 - val_sparse_categorical_accuracy: 0.9968\n"
     ]
    }
   ],
   "source": [
    "# Training Model 1\n",
    "history1 = model_1.fit(    \n",
    "    train_dataset,\n",
    "    epochs=30,\n",
    "    shuffle=True,\n",
    "    validation_data = (validation_dataset)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "87/87 [==============================] - 16s 139ms/step - loss: 2.5268 - sparse_categorical_accuracy: 0.3691 - val_loss: 0.8988 - val_sparse_categorical_accuracy: 0.9123\n",
      "Epoch 2/30\n",
      "87/87 [==============================] - 10s 110ms/step - loss: 0.2476 - sparse_categorical_accuracy: 0.9342 - val_loss: 23.5757 - val_sparse_categorical_accuracy: 0.0779\n",
      "Epoch 3/30\n",
      "87/87 [==============================] - 10s 108ms/step - loss: 0.0808 - sparse_categorical_accuracy: 0.9770 - val_loss: 23.5948 - val_sparse_categorical_accuracy: 0.0455\n",
      "Epoch 4/30\n",
      "87/87 [==============================] - 10s 110ms/step - loss: 0.0762 - sparse_categorical_accuracy: 0.9773 - val_loss: 25.0027 - val_sparse_categorical_accuracy: 0.0357\n",
      "Epoch 5/30\n",
      "87/87 [==============================] - 10s 111ms/step - loss: 0.0731 - sparse_categorical_accuracy: 0.9795 - val_loss: 21.1595 - val_sparse_categorical_accuracy: 0.0357\n",
      "Epoch 6/30\n",
      "87/87 [==============================] - 11s 115ms/step - loss: 0.0672 - sparse_categorical_accuracy: 0.9809 - val_loss: 21.5560 - val_sparse_categorical_accuracy: 0.0357\n",
      "Epoch 7/30\n",
      "87/87 [==============================] - 10s 111ms/step - loss: 0.0457 - sparse_categorical_accuracy: 0.9881 - val_loss: 17.4330 - val_sparse_categorical_accuracy: 0.0487\n",
      "Epoch 8/30\n",
      "87/87 [==============================] - 10s 110ms/step - loss: 0.0443 - sparse_categorical_accuracy: 0.9867 - val_loss: 27.1873 - val_sparse_categorical_accuracy: 0.0357\n",
      "Epoch 9/30\n",
      "87/87 [==============================] - 10s 111ms/step - loss: 0.0298 - sparse_categorical_accuracy: 0.9932 - val_loss: 28.6865 - val_sparse_categorical_accuracy: 0.0487\n",
      "Epoch 10/30\n",
      "87/87 [==============================] - 10s 110ms/step - loss: 0.0499 - sparse_categorical_accuracy: 0.9842 - val_loss: 32.7295 - val_sparse_categorical_accuracy: 0.0487\n",
      "Epoch 11/30\n",
      "87/87 [==============================] - 10s 111ms/step - loss: 0.0349 - sparse_categorical_accuracy: 0.9910 - val_loss: 28.8760 - val_sparse_categorical_accuracy: 0.0357\n",
      "Epoch 12/30\n",
      "87/87 [==============================] - 10s 112ms/step - loss: 0.0231 - sparse_categorical_accuracy: 0.9939 - val_loss: 27.8960 - val_sparse_categorical_accuracy: 0.0487\n",
      "Epoch 13/30\n",
      "87/87 [==============================] - 10s 112ms/step - loss: 0.0249 - sparse_categorical_accuracy: 0.9914 - val_loss: 32.0158 - val_sparse_categorical_accuracy: 0.0487\n",
      "Epoch 14/30\n",
      "87/87 [==============================] - 10s 111ms/step - loss: 0.0182 - sparse_categorical_accuracy: 0.9932 - val_loss: 36.6200 - val_sparse_categorical_accuracy: 0.0487\n",
      "Epoch 15/30\n",
      "87/87 [==============================] - 10s 114ms/step - loss: 0.0438 - sparse_categorical_accuracy: 0.9885 - val_loss: 26.5402 - val_sparse_categorical_accuracy: 0.0487\n",
      "Epoch 16/30\n",
      "87/87 [==============================] - 10s 112ms/step - loss: 0.0231 - sparse_categorical_accuracy: 0.9921 - val_loss: 26.7868 - val_sparse_categorical_accuracy: 0.0487\n",
      "Epoch 17/30\n",
      "87/87 [==============================] - 10s 110ms/step - loss: 0.0131 - sparse_categorical_accuracy: 0.9950 - val_loss: 31.2467 - val_sparse_categorical_accuracy: 0.0487\n",
      "Epoch 18/30\n",
      "87/87 [==============================] - 10s 113ms/step - loss: 0.0270 - sparse_categorical_accuracy: 0.9921 - val_loss: 28.0671 - val_sparse_categorical_accuracy: 0.0487\n",
      "Epoch 19/30\n",
      "87/87 [==============================] - 11s 114ms/step - loss: 0.0313 - sparse_categorical_accuracy: 0.9906 - val_loss: 31.5852 - val_sparse_categorical_accuracy: 0.0487\n",
      "Epoch 20/30\n",
      "87/87 [==============================] - 10s 112ms/step - loss: 0.0251 - sparse_categorical_accuracy: 0.9935 - val_loss: 32.7308 - val_sparse_categorical_accuracy: 0.0487\n",
      "Epoch 21/30\n",
      "87/87 [==============================] - 10s 114ms/step - loss: 0.0588 - sparse_categorical_accuracy: 0.9867 - val_loss: 39.3150 - val_sparse_categorical_accuracy: 0.0487\n",
      "Epoch 22/30\n",
      "87/87 [==============================] - 11s 114ms/step - loss: 0.0476 - sparse_categorical_accuracy: 0.9878 - val_loss: 30.4869 - val_sparse_categorical_accuracy: 0.0422\n",
      "Epoch 23/30\n",
      "87/87 [==============================] - 10s 114ms/step - loss: 0.0246 - sparse_categorical_accuracy: 0.9939 - val_loss: 37.6322 - val_sparse_categorical_accuracy: 0.0357\n",
      "Epoch 24/30\n",
      "87/87 [==============================] - 10s 110ms/step - loss: 0.0174 - sparse_categorical_accuracy: 0.9950 - val_loss: 41.3449 - val_sparse_categorical_accuracy: 0.0357\n",
      "Epoch 25/30\n",
      "87/87 [==============================] - 10s 109ms/step - loss: 0.0386 - sparse_categorical_accuracy: 0.9928 - val_loss: 41.1448 - val_sparse_categorical_accuracy: 0.0357\n",
      "Epoch 26/30\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 0.0343 - sparse_categorical_accuracy: 0.9917 - val_loss: 40.6883 - val_sparse_categorical_accuracy: 0.0487\n",
      "Epoch 27/30\n",
      "87/87 [==============================] - 8s 84ms/step - loss: 0.0172 - sparse_categorical_accuracy: 0.9950 - val_loss: 45.6515 - val_sparse_categorical_accuracy: 0.0649\n",
      "Epoch 28/30\n",
      "87/87 [==============================] - 8s 84ms/step - loss: 0.0388 - sparse_categorical_accuracy: 0.9881 - val_loss: 40.4782 - val_sparse_categorical_accuracy: 0.0422\n",
      "Epoch 29/30\n",
      "87/87 [==============================] - 10s 113ms/step - loss: 0.0378 - sparse_categorical_accuracy: 0.9910 - val_loss: 42.0297 - val_sparse_categorical_accuracy: 0.0487\n",
      "Epoch 30/30\n",
      "87/87 [==============================] - 10s 109ms/step - loss: 0.0302 - sparse_categorical_accuracy: 0.9924 - val_loss: 34.0295 - val_sparse_categorical_accuracy: 0.0649\n"
     ]
    }
   ],
   "source": [
    "# Training Model 2\n",
    "history2 = model_2.fit(    \n",
    "    train_dataset,\n",
    "    epochs=30,\n",
    "    shuffle=True,\n",
    "    validation_data = (validation_dataset)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "87/87 [==============================] - 34s 273ms/step - loss: 2.0481 - sparse_categorical_accuracy: 0.3917 - val_loss: 3.6334 - val_sparse_categorical_accuracy: 0.2468\n",
      "Epoch 2/30\n",
      "87/87 [==============================] - 13s 137ms/step - loss: 0.4149 - sparse_categorical_accuracy: 0.8651 - val_loss: 38.4023 - val_sparse_categorical_accuracy: 0.2208\n",
      "Epoch 3/30\n",
      "87/87 [==============================] - 13s 138ms/step - loss: 0.2008 - sparse_categorical_accuracy: 0.9450 - val_loss: 25.1020 - val_sparse_categorical_accuracy: 0.1461\n",
      "Epoch 4/30\n",
      "87/87 [==============================] - 13s 139ms/step - loss: 0.1757 - sparse_categorical_accuracy: 0.9478 - val_loss: 2.5688 - val_sparse_categorical_accuracy: 0.6006\n",
      "Epoch 5/30\n",
      "87/87 [==============================] - 13s 138ms/step - loss: 0.0963 - sparse_categorical_accuracy: 0.9737 - val_loss: 5.8490 - val_sparse_categorical_accuracy: 0.3604\n",
      "Epoch 6/30\n",
      "87/87 [==============================] - 13s 139ms/step - loss: 0.1112 - sparse_categorical_accuracy: 0.9669 - val_loss: 0.2579 - val_sparse_categorical_accuracy: 0.9318\n",
      "Epoch 7/30\n",
      "87/87 [==============================] - 13s 138ms/step - loss: 0.1061 - sparse_categorical_accuracy: 0.9683 - val_loss: 9.2605 - val_sparse_categorical_accuracy: 0.2597\n",
      "Epoch 8/30\n",
      "87/87 [==============================] - 12s 136ms/step - loss: 0.0749 - sparse_categorical_accuracy: 0.9777 - val_loss: 0.8603 - val_sparse_categorical_accuracy: 0.7175\n",
      "Epoch 9/30\n",
      "87/87 [==============================] - 13s 141ms/step - loss: 0.0574 - sparse_categorical_accuracy: 0.9853 - val_loss: 0.6230 - val_sparse_categorical_accuracy: 0.8377\n",
      "Epoch 10/30\n",
      "87/87 [==============================] - 13s 140ms/step - loss: 0.0516 - sparse_categorical_accuracy: 0.9842 - val_loss: 8.5928 - val_sparse_categorical_accuracy: 0.3409\n",
      "Epoch 11/30\n",
      "87/87 [==============================] - 13s 139ms/step - loss: 0.0507 - sparse_categorical_accuracy: 0.9849 - val_loss: 14.6717 - val_sparse_categorical_accuracy: 0.3149\n",
      "Epoch 12/30\n",
      "87/87 [==============================] - 13s 138ms/step - loss: 0.0579 - sparse_categorical_accuracy: 0.9845 - val_loss: 14.6992 - val_sparse_categorical_accuracy: 0.2175\n",
      "Epoch 13/30\n",
      "87/87 [==============================] - 13s 141ms/step - loss: 0.0322 - sparse_categorical_accuracy: 0.9899 - val_loss: 2.1610 - val_sparse_categorical_accuracy: 0.6656\n",
      "Epoch 14/30\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 0.0225 - sparse_categorical_accuracy: 0.9921 - val_loss: 2.1411 - val_sparse_categorical_accuracy: 0.7013\n",
      "Epoch 15/30\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 0.0467 - sparse_categorical_accuracy: 0.9863 - val_loss: 14.7012 - val_sparse_categorical_accuracy: 0.2857\n",
      "Epoch 16/30\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 0.0461 - sparse_categorical_accuracy: 0.9853 - val_loss: 3.9097 - val_sparse_categorical_accuracy: 0.4318\n",
      "Epoch 17/30\n",
      "87/87 [==============================] - 13s 141ms/step - loss: 0.0326 - sparse_categorical_accuracy: 0.9888 - val_loss: 1.6834 - val_sparse_categorical_accuracy: 0.6656\n",
      "Epoch 18/30\n",
      "87/87 [==============================] - 13s 141ms/step - loss: 0.0275 - sparse_categorical_accuracy: 0.9924 - val_loss: 6.0157 - val_sparse_categorical_accuracy: 0.3279\n",
      "Epoch 19/30\n",
      "87/87 [==============================] - 13s 142ms/step - loss: 0.0272 - sparse_categorical_accuracy: 0.9928 - val_loss: 23.4782 - val_sparse_categorical_accuracy: 0.2890\n",
      "Epoch 20/30\n",
      "87/87 [==============================] - 13s 137ms/step - loss: 0.0462 - sparse_categorical_accuracy: 0.9845 - val_loss: 0.0415 - val_sparse_categorical_accuracy: 0.9870\n",
      "Epoch 21/30\n",
      "87/87 [==============================] - 13s 140ms/step - loss: 0.0323 - sparse_categorical_accuracy: 0.9899 - val_loss: 15.0468 - val_sparse_categorical_accuracy: 0.1916\n",
      "Epoch 22/30\n",
      "87/87 [==============================] - 13s 140ms/step - loss: 0.0200 - sparse_categorical_accuracy: 0.9939 - val_loss: 20.5498 - val_sparse_categorical_accuracy: 0.3084\n",
      "Epoch 23/30\n",
      "87/87 [==============================] - 13s 146ms/step - loss: 0.0256 - sparse_categorical_accuracy: 0.9942 - val_loss: 5.4647 - val_sparse_categorical_accuracy: 0.4416\n",
      "Epoch 24/30\n",
      "87/87 [==============================] - 10s 113ms/step - loss: 0.0430 - sparse_categorical_accuracy: 0.9860 - val_loss: 9.5315 - val_sparse_categorical_accuracy: 0.3929\n",
      "Epoch 25/30\n",
      "87/87 [==============================] - 10s 106ms/step - loss: 0.0416 - sparse_categorical_accuracy: 0.9871 - val_loss: 9.7630 - val_sparse_categorical_accuracy: 0.3377\n",
      "Epoch 26/30\n",
      "87/87 [==============================] - 10s 113ms/step - loss: 0.0204 - sparse_categorical_accuracy: 0.9932 - val_loss: 28.4930 - val_sparse_categorical_accuracy: 0.1299\n",
      "Epoch 27/30\n",
      "87/87 [==============================] - 13s 137ms/step - loss: 0.0144 - sparse_categorical_accuracy: 0.9950 - val_loss: 10.6105 - val_sparse_categorical_accuracy: 0.3831\n",
      "Epoch 28/30\n",
      "87/87 [==============================] - 13s 138ms/step - loss: 0.0156 - sparse_categorical_accuracy: 0.9950 - val_loss: 26.9795 - val_sparse_categorical_accuracy: 0.2013\n",
      "Epoch 29/30\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 0.0317 - sparse_categorical_accuracy: 0.9924 - val_loss: 4.2126 - val_sparse_categorical_accuracy: 0.4675\n",
      "Epoch 30/30\n",
      "87/87 [==============================] - 13s 138ms/step - loss: 0.0125 - sparse_categorical_accuracy: 0.9942 - val_loss: 0.0127 - val_sparse_categorical_accuracy: 0.9968\n"
     ]
    }
   ],
   "source": [
    "# Training Model 3\n",
    "history3 = model_3.fit(    \n",
    "    train_dataset,\n",
    "    epochs=30,\n",
    "    shuffle=True,\n",
    "    validation_data = (validation_dataset)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/Model_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/Model_1\\assets\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/Model_2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/Model_2\\assets\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/Model_3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/Model_3\\assets\n"
     ]
    }
   ],
   "source": [
    "modelFileDirectoryName1 = 'saved_model/Model_1'\n",
    "modelFileDirectoryName2 = 'saved_model/Model_2'\n",
    "modelFileDirectoryName3 = 'saved_model/Model_3'\n",
    "model_1.save(modelFileDirectoryName1)\n",
    "model_2.save(modelFileDirectoryName2)\n",
    "model_3.save(modelFileDirectoryName3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation and History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 36ms/step - loss: 5.3646 - sparse_categorical_accuracy: 0.9583\n",
      "Test accuracy: 95.83%\n"
     ]
    }
   ],
   "source": [
    "# Model 1\n",
    "loss, acc = model_1.evaluate(test_dataset)\n",
    "print(\"Test accuracy: {:5.2f}%\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 18ms/step - loss: 33.6375 - sparse_categorical_accuracy: 0.0609\n",
      "Test accuracy:  6.09%\n"
     ]
    }
   ],
   "source": [
    "# Model 2\n",
    "loss, acc = model_2.evaluate(test_dataset)\n",
    "print(\"Test accuracy: {:5.2f}%\".format(100 * acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 26ms/step - loss: 0.0051 - sparse_categorical_accuracy: 1.0000\n",
      "Test accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Model 3\n",
    "loss, acc = model_3.evaluate(test_dataset)\n",
    "print(\"Test accuracy: {:5.2f}%\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a6fa6954ade73bba0c808e45fb6e3f3b51cdc4ac8ab9c110f2c0fbb65783927d"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
